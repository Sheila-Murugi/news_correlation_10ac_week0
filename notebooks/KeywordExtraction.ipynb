{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a809464-be1f-4cb2-959b-040529479ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most important words:\n",
      "the: 0.07521244007411275\n",
      "to: 0.05110932088798397\n",
      "of: 0.04837162851338603\n",
      "in: 0.04371437474730651\n",
      "and: 0.04339376494517135\n",
      "on: 0.032849064844609505\n",
      "chars: 0.032717766873407\n",
      "maldives: 0.03203666592134964\n",
      "for: 0.030289572196611755\n",
      "as: 0.028385765907014263\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load data from CSV files\n",
    "data = pd.read_csv('C:/Users/HP/Desktop/KARUGIII/data.csv/rating.csv')\n",
    "domains_location = pd.read_csv('C:/Users/HP/Desktop/KARUGIII/domains_location.csv')\n",
    "\n",
    "# Extract headlines and news bodies\n",
    "headlines = data['title'].tolist()\n",
    "news_bodies = data['content'].tolist()\n",
    "\n",
    "# Combine headlines and news bodies\n",
    "text_data = [f\"{headline} {news_body}\" for headline, news_body in zip(headlines, news_bodies)]\n",
    "\n",
    "# Set the sample size\n",
    "sample_size = 100\n",
    "\n",
    "# Down-sample the data to a sample size of 100\n",
    "if len(text_data) > sample_size:\n",
    "    text_data = text_data[:sample_size]\n",
    "\n",
    "# Create TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(text_data)\n",
    "\n",
    "## Perform analysis\n",
    "# For example, calculate the top N most important words using TF-IDF scores\n",
    "\n",
    "# Get the feature names (words) from the TF-IDF vectorizer\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Get the TF-IDF scores for each feature (word)\n",
    "tfidf_scores = X.toarray()\n",
    "\n",
    "# Calculate the mean TF-IDF score for each word across all documents\n",
    "mean_tfidf_scores = tfidf_scores.mean(axis=0)\n",
    "\n",
    "# Sort the words based on their mean TF-IDF scores in descending order\n",
    "sorted_words_indices = mean_tfidf_scores.argsort()[::-1]\n",
    "\n",
    "# Print the top N most important words and their TF-IDF scores\n",
    "top_n = 10\n",
    "print(f\"Top {top_n} most important words:\")\n",
    "for i in range(top_n):\n",
    "    word_index = sorted_words_indices[i]\n",
    "    word = feature_names[word_index]\n",
    "    tfidf_score = mean_tfidf_scores[word_index]\n",
    "    print(f\"{word}: {tfidf_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba1b749-b16a-4407-adb4-f73961e5fd76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
